{"cells":[{"cell_type":"code","source":["#Create Spark session\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"Credit Card Fraud Detection\").getOrCreate()\nspark"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.172.253.190:40092\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":1},{"cell_type":"code","source":["#Import needed libraries\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.classification import  RandomForestClassifier\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, VectorSlicer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["#Read credit card csv file\ncredit_df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").load(\"/FileStore/tables/creditcard.csv\")\ntype(credit_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[87]: pyspark.sql.dataframe.DataFrame</div>"]}}],"execution_count":3},{"cell_type":"code","source":["#Display data to know features and traget label\ndisplay(credit_df.select('*').limit(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Time</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>V10</th><th>V11</th><th>V12</th><th>V13</th><th>V14</th><th>V15</th><th>V16</th><th>V17</th><th>V18</th><th>V19</th><th>V20</th><th>V21</th><th>V22</th><th>V23</th><th>V24</th><th>V25</th><th>V26</th><th>V27</th><th>V28</th><th>Amount</th><th>Class</th></tr></thead><tbody><tr><td>0</td><td>-1.3598071336738</td><td>-0.0727811733098497</td><td>2.53634673796914</td><td>1.37815522427443</td><td>-0.338320769942518</td><td>0.462387777762292</td><td>0.239598554061257</td><td>0.0986979012610507</td><td>0.363786969611213</td><td>0.0907941719789316</td><td>-0.551599533260813</td><td>-0.617800855762348</td><td>-0.991389847235408</td><td>-0.311169353699879</td><td>1.46817697209427</td><td>-0.470400525259478</td><td>0.207971241929242</td><td>0.0257905801985591</td><td>0.403992960255733</td><td>0.251412098239705</td><td>-0.018306777944153</td><td>0.277837575558899</td><td>-0.110473910188767</td><td>0.0669280749146731</td><td>0.128539358273528</td><td>-0.189114843888824</td><td>0.133558376740387</td><td>-0.0210530534538215</td><td>149.62</td><td>0</td></tr><tr><td>0</td><td>1.19185711131486</td><td>0.26615071205963</td><td>0.16648011335321</td><td>0.448154078460911</td><td>0.0600176492822243</td><td>-0.0823608088155687</td><td>-0.0788029833323113</td><td>0.0851016549148104</td><td>-0.255425128109186</td><td>-0.166974414004614</td><td>1.61272666105479</td><td>1.06523531137287</td><td>0.48909501589608</td><td>-0.143772296441519</td><td>0.635558093258208</td><td>0.463917041022171</td><td>-0.114804663102346</td><td>-0.183361270123994</td><td>-0.145783041325259</td><td>-0.0690831352230203</td><td>-0.225775248033138</td><td>-0.638671952771851</td><td>0.101288021253234</td><td>-0.339846475529127</td><td>0.167170404418143</td><td>0.125894532368176</td><td>-0.00898309914322813</td><td>0.0147241691924927</td><td>2.69</td><td>0</td></tr><tr><td>1</td><td>-1.35835406159823</td><td>-1.34016307473609</td><td>1.77320934263119</td><td>0.379779593034328</td><td>-0.503198133318193</td><td>1.80049938079263</td><td>0.791460956450422</td><td>0.247675786588991</td><td>-1.51465432260583</td><td>0.207642865216696</td><td>0.624501459424895</td><td>0.066083685268831</td><td>0.717292731410831</td><td>-0.165945922763554</td><td>2.34586494901581</td><td>-2.89008319444231</td><td>1.10996937869599</td><td>-0.121359313195888</td><td>-2.26185709530414</td><td>0.524979725224404</td><td>0.247998153469754</td><td>0.771679401917229</td><td>0.909412262347719</td><td>-0.689280956490685</td><td>-0.327641833735251</td><td>-0.139096571514147</td><td>-0.0553527940384261</td><td>-0.0597518405929204</td><td>378.66</td><td>0</td></tr><tr><td>1</td><td>-0.966271711572087</td><td>-0.185226008082898</td><td>1.79299333957872</td><td>-0.863291275036453</td><td>-0.0103088796030823</td><td>1.24720316752486</td><td>0.23760893977178</td><td>0.377435874652262</td><td>-1.38702406270197</td><td>-0.0549519224713749</td><td>-0.226487263835401</td><td>0.178228225877303</td><td>0.507756869957169</td><td>-0.28792374549456</td><td>-0.631418117709045</td><td>-1.0596472454325</td><td>-0.684092786345479</td><td>1.96577500349538</td><td>-1.2326219700892</td><td>-0.208037781160366</td><td>-0.108300452035545</td><td>0.00527359678253453</td><td>-0.190320518742841</td><td>-1.17557533186321</td><td>0.647376034602038</td><td>-0.221928844458407</td><td>0.0627228487293033</td><td>0.0614576285006353</td><td>123.5</td><td>0</td></tr><tr><td>2</td><td>-1.15823309349523</td><td>0.877736754848451</td><td>1.548717846511</td><td>0.403033933955121</td><td>-0.407193377311653</td><td>0.0959214624684256</td><td>0.592940745385545</td><td>-0.270532677192282</td><td>0.817739308235294</td><td>0.753074431976354</td><td>-0.822842877946363</td><td>0.53819555014995</td><td>1.3458515932154</td><td>-1.11966983471731</td><td>0.175121130008994</td><td>-0.451449182813529</td><td>-0.237033239362776</td><td>-0.0381947870352842</td><td>0.803486924960175</td><td>0.408542360392758</td><td>-0.00943069713232919</td><td>0.79827849458971</td><td>-0.137458079619063</td><td>0.141266983824769</td><td>-0.206009587619756</td><td>0.502292224181569</td><td>0.219422229513348</td><td>0.215153147499206</td><td>69.99</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#Check number of fraud vs number of none fraud records\nclassFreq = credit_df.groupBy(\"Class\").count()\nclassFreq.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------+\nClass| count|\n+-----+------+\n    1|   492|\n    0|284315|\n+-----+------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["#Convert the data to pandas \nimport pandas as pd\ndata_pd = credit_df.toPandas()\ndata = data_pd.sample(frac=1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/pyarrow/__init__.py:152: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n  warnings.warn(&#34;pyarrow.open_stream is deprecated, please use &#34;\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["#Plot Imbalanced dataset\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nsns.countplot(x='Class', data=data)\nplt.title('Imbalanced Distubited Classes', fontsize=14)\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql.window import Window\n\n#dfff = spark.createDataFrame(new_df)\nwin = Window().orderBy('Time')\ndfff = credit_df.withColumn(\"idx\", row_number().over(win))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["#Machine learning model Gradient-Boosted Trees (GBTs) \nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import VectorIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.linalg import DenseVector\n\ntraining_df = dfff.rdd.map(lambda x: (DenseVector(x[0:29]),x[30],x[31])) # Dense Vector required in spark to train the data\ntraining_df = spark.createDataFrame(training_df,[\"features\",\"label\",\"index\"])\ntraining_df = training_df.select(\"index\",\"features\",\"label\")\n\n#Split Dataset to train and test\ntrain_data_before, test_data_before = training_df.randomSplit([.8,.2],seed=1234)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["#count the training data\ntrain_data_before.groupBy(\"label\").count().show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------+\nlabel| count|\n+-----+------+\n    0|227418|\n    1|   376|\n+-----+------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["#Count testing data\ntest_data_before.groupBy(\"label\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+\nlabel|count|\n+-----+-----+\n    0|56897|\n    1|  116|\n+-----+-----+\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["#Train and predict using Gradient-Boosted Trees (GBTs) Classifier (First Classifier before handling imbalanced dataset)\ngbt_before = GBTClassifier(featuresCol=\"features\", maxIter=100,maxDepth=8)\nmodel_before = gbt_before.fit(train_data_before)\npredictions_gbt_before = model_before.transform(test_data_before)\npredictions_gbt_before.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\nprediction|count|\n+----------+-----+\n       0.0|56914|\n       1.0|   99|\n+----------+-----+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["#We use the BinaryClassificationEvaluator to evaluate our models, which uses areaUnderROC as the default metric.\nevaluator_gbt_before = BinaryClassificationEvaluator()\nevaluator_gbt_before.evaluate(predictions_gbt_before)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[97]: 0.9693759988555609</div>"]}}],"execution_count":13},{"cell_type":"code","source":["#Check count of fraud and none fraud predictions\npredictions_gbt_before = predictions_gbt_before.withColumn(\"fraudPrediction\",when((predictions_gbt_before.label==1)&(predictions_gbt_before.prediction==1),1).otherwise(0))\npredictions_gbt_before.groupBy(\"fraudPrediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+-----+\nfraudPrediction|count|\n+---------------+-----+\n              1|   95|\n              0|56918|\n+---------------+-----+\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["#Calculated Recall\nfrom pyspark.sql.functions import col\naccurateFraud_gbt_before = predictions_gbt_before.groupBy(\"fraudPrediction\").count().where(predictions_gbt_before.fraudPrediction==1).head()[1]\ntotalFraud_gbt_before = predictions_gbt_before.groupBy(\"label\").count().where(predictions_gbt_before.label==1).head()[1]\nFraudPredictionAccuracy_gbt_before = (accurateFraud_gbt_before/totalFraud_gbt_before)*100\nprint(FraudPredictionAccuracy_gbt_before)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">81.89655172413794\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["#Calculating Confusion matrix\ntp_gbt_before = predictions_gbt_before[(predictions_gbt_before.label == 1) & (predictions_gbt_before.prediction == 1)].count()\ntn_gbt_before = predictions_gbt_before[(predictions_gbt_before.label == 0) & (predictions_gbt_before.prediction == 0)].count()\nfp_gbt_before = predictions_gbt_before[(predictions_gbt_before.label == 0) & (predictions_gbt_before.prediction == 1)].count()\nfn_gbt_before = predictions_gbt_before[(predictions_gbt_before.label == 1) & (predictions_gbt_before.prediction == 0)].count()\n\n\nprint(\"True Positive: \",tp_gbt_before,\"\\nTrue Negative: \",tn_gbt_before,\"\\nFalse Positive: \",fp_gbt_before,\"\\nFalse Negative: \",fn_gbt_before)\nprint(\"Recall: \",tp_gbt_before/(tp_gbt_before+fn_gbt_before))\nprint(\"Precision: \", tp_gbt_before/(tp_gbt_before+fp_gbt_before))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">True Positive:  95 \nTrue Negative:  56893 \nFalse Positive:  4 \nFalse Negative:  21\nRecall:  0.8189655172413793\nPrecision:  0.9595959595959596\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["##Train and predict using Random Forest Classifier Classifier (Second Classifier before handling imbalanced dataset)\nfrom pyspark.ml.classification import RandomForestClassifier\nrf_before = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\nrfModel_before = rf_before.fit(train_data_before)\npredictions_rf_before = rfModel_before.transform(test_data_before)\npredictions_rf_before.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\nprediction|count|\n+----------+-----+\n       0.0|56908|\n       1.0|  105|\n+----------+-----+\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["#We use the BinaryClassificationEvaluator to evaluate our models, which uses areaUnderROC as the default metric.\nevaluator_rf_before = BinaryClassificationEvaluator()\nevaluator_rf_before.evaluate(predictions_rf_before)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[102]: 0.9628293837684906</div>"]}}],"execution_count":18},{"cell_type":"code","source":["#Check count of fraud and none fraud predictions\npredictions_rf_before = predictions_rf_before.withColumn(\"fraudPrediction\",when((predictions_rf_before.label==1)&(predictions_rf_before.prediction==1),1).otherwise(0))\npredictions_rf_before.groupBy(\"fraudPrediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+-----+\nfraudPrediction|count|\n+---------------+-----+\n              1|   92|\n              0|56921|\n+---------------+-----+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["#Calculated Recall\nfrom pyspark.sql.functions import col\naccurateFraud_rf_before = predictions_rf_before.groupBy(\"fraudPrediction\").count().where(predictions_rf_before.fraudPrediction==1).head()[1]\ntotalFraud_rf_before = predictions_rf_before.groupBy(\"label\").count().where(predictions_rf_before.label==1).head()[1]\nFraudPredictionAccuracy_rf_before = (accurateFraud_rf_before/totalFraud_rf_before)*100\nprint(FraudPredictionAccuracy_rf_before)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">79.3103448275862\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["#Calculating Confusion matrix\ntp_rf_before = predictions_rf_before[(predictions_rf_before.label == 1) & (predictions_rf_before.prediction == 1)].count()\ntn_rf_before = predictions_rf_before[(predictions_rf_before.label == 0) & (predictions_rf_before.prediction == 0)].count()\nfp_rf_before = predictions_rf_before[(predictions_rf_before.label == 0) & (predictions_rf_before.prediction == 1)].count()\nfn_rf_before = predictions_rf_before[(predictions_rf_before.label == 1) & (predictions_rf_before.prediction == 0)].count()\n\n\nprint(\"True Positive: \",tp_rf_before,\"\\nTrue Negative: \",tn_rf_before,\"\\nFalse Positive: \",fp_rf_before,\"\\nFalse Negative: \",fn_rf_before)\nprint(\"Recall: \",tp_rf_before/(tp_rf_before+fn_rf_before))\nprint(\"Precision: \", tp_rf_before/(tp_rf_before+fp_rf_before))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">True Positive:  92 \nTrue Negative:  56884 \nFalse Positive:  13 \nFalse Negative:  24\nRecall:  0.7931034482758621\nPrecision:  0.8761904761904762\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["#Check Imbalanced dataset counts\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nprint(\"Distribution of Classes in subsample dataset\")\nprint(data['Class'].value_counts())\nprint(len(data))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Distribution of Classes in subsample dataset\n0    284315\n1       492\nName: Class, dtype: int64\n284807\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["#Down Sampling technique to handle imbalanced dataset\n#Take sample to reduce datasets to be the same (means take 492 sample from each Class) to escape from imbalance datasets problem\n#import pandas as pd\n#data_pd = credit_df.toPandas()\n#data = data_pd.sample(frac=1)\n\n#take same records from class 0 as class one 492 records\nfraud_df = data.loc[data['Class'] == 1]\nnon_fraud_df = data.loc[data['Class'] == 0][:492]\n\nnormal_distribution_df = pd.concat([fraud_df, non_fraud_df])\n\n#Shuffle dataframe rows\nnew_df = normal_distribution_df.sample(frac=1, random_state=42)\nnew_df.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[107]: (984, 31)</div>"]}}],"execution_count":23},{"cell_type":"code","source":["#Plot to show data balanced after downsampling to handle Imbalaced dataset\n\nprint(\"Distribution of Classes in subsample dataset\")\nprint(new_df['Class'].value_counts())\nprint(len(new_df))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Distribution of Classes in subsample dataset\n1    492\n0    492\nName: Class, dtype: int64\n984\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["#Plot dataset after Under Sampling\nsns.countplot(x='Class', data=new_df)\nplt.title('Sampled Equally Distubited Classes', fontsize=14)\ndisplay(plt.show())\n"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Check feature importance that affect model\nf, (ax1,ax2) = plt.subplots(2,1, figsize=(24,20))\n\ncorr = data.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\nax1.set_title(\"Imbalanced dataset Correlation Matrix\", fontsize=14)\n\nsub_sample_corr = new_df.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\nax2.set_title('Subsample Correlation Matrix', fontsize=14)\ndisplay(plt.show())\n"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#Check outliers using Boxplot\nf, axes = plt.subplots(ncols=4, figsize=(20,4))\n\n#Negative Correlations with our Class (lower our feature value more likely it will fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V17\", data=new_df, ax=axes[0])\naxes[0].set_title('V17 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df, ax=axes[1])\naxes[1].set_title('V14 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=axes[2])\naxes[2].set_title('V12 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=axes[3])\naxes[3].set_title('V10 vs Class Negative Correlation')\ndisplay(plt.show())\n\n#----------------------------------------------------------------------------------------\n\n\nf, axes = plt.subplots(ncols=4, figsize=(20,4))\n#Positive Correlations with our Class (the higher the feature the probability increases that it will fraud transaction)\n\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df, ax=axes[0])\naxes[0].set_title('V11 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df, ax=axes[1])\naxes[1].set_title('V4 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df, ax=axes[2])\naxes[2].set_title('V2 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V19\", data=new_df, ax=axes[3])\naxes[3].set_title('V19 vs Class Positive Correlation')\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["from scipy.stats import norm\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,6))\n\nv14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values\nsns.distplot(v14_fraud_dist, ax=ax1, fit=norm, color='#FB8861')\nax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values\nsns.distplot(v12_fraud_dist, ax=ax2, fit=norm, color='#FB8861')\nax2.set_title('12 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values\nsns.distplot(v10_fraud_dist, ax=ax3, fit=norm, color='#FB8861')\nax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["#Removing Outliers\nimport numpy as np\n\n#V14 Removing Outliers (Highest Negative Correlated with Labels)\nv14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\nprint('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\nv14_iqr = q75 - q25\nprint('iqr:{}'.format(v14_iqr))\n\nv14_cut_off = v14_iqr * 1.5\nv14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\nprint('Cut Off: {}'.format(v14_cut_off)) \nprint('V14 Lower: {}'.format(v14_lower))\nprint('V14 Upper: {}'.format(v14_upper))\n\noutliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\nprint('Feature V14 Outliers for Fraud Cases {}'.format(len(outliers)))\nprint('V14 outliers: {}'.format(outliers))\n\nnew_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\nprint('Number of Instances after outliers removal {}'.format(len(new_df)))\nprint('---' * 44)\n\n\n#V12 Removing Outliers (Highest Negative Correlated with Labels)\nV12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(V12_fraud, 25), np.percentile(V12_fraud, 75)\nprint('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\nV12_iqr = q75 - q25\nprint('iqr:{}'.format(V12_iqr))\n\nV12_cut_off = V12_iqr * 1.5\nV12_lower, V12_upper = q25 - V12_cut_off, q75 + V12_cut_off\nprint('Cut Off: {}'.format(V12_cut_off)) \nprint('V12 Lower: {}'.format(V12_lower))\nprint('V12 Upper: {}'.format(V12_upper))\n\noutliers = [x for x in V12_fraud if x < V12_lower or x > V12_upper]\nprint('Feature V12 Outliers for Fraud Cases {}'.format(len(outliers)))\nprint('V12 outliers: {}'.format(outliers))\n\nnew_df = new_df.drop(new_df[(new_df['V12'] > V12_upper) | (new_df['V12'] < V12_lower)].index)\nprint('Number of Instances after outliers removal {}'.format(len(new_df)))\nprint('---' * 44)\n\n#V10 Removing Outliers (Highest Negative Correlated with Labels)\nV10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(V10_fraud, 25), np.percentile(V10_fraud, 75)\nprint('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\nV10_iqr = q75 - q25\nprint('iqr:{}'.format(V10_iqr))\n\nV10_cut_off = V10_iqr * 1.5\nV10_lower, V10_upper = q25 - V10_cut_off, q75 + V10_cut_off\nprint('Cut Off: {}'.format(V10_cut_off)) \nprint('V10 Lower: {}'.format(V10_lower))\nprint('V10 Upper: {}'.format(V10_upper))\n\noutliers = [x for x in V10_fraud if x < V10_lower or x > V10_upper]\nprint('Feature V10 Outliers for Fraud Cases {}'.format(len(outliers)))\nprint('V10 outliers: {}'.format(outliers))\n\nnew_df = new_df.drop(new_df[(new_df['V10'] > V10_upper) | (new_df['V10'] < V10_lower)].index)\n\nprint('Number of Instances after outliers removal {}'.format(len(new_df)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Quartile 25: -9.692722964972385 | Quartile 75: -4.282820849486866\niqr:5.409902115485519\nCut Off: 8.114853173228278\nV14 Lower: -17.807576138200663\nV14 Upper: 3.8320323237414122\nFeature V14 Outliers for Fraud Cases 4\nV14 outliers: [-18.8220867423816, -19.2143254902614, -18.0499976898594, -18.4937733551053]\nNumber of Instances after outliers removal 980\n------------------------------------------------------------------------------------------------------------------------------------\nQuartile 25: -8.67303320439115 | Quartile 75: -2.893030568676315\niqr:5.780002635714835\nCut Off: 8.670003953572252\nV12 Lower: -17.3430371579634\nV12 Upper: 5.776973384895937\nFeature V12 Outliers for Fraud Cases 4\nV12 outliers: [-18.4311310279993, -18.0475965708216, -18.6837146333443, -18.5536970096458]\nNumber of Instances after outliers removal 976\n------------------------------------------------------------------------------------------------------------------------------------\nQuartile 25: -7.466658535821847 | Quartile 75: -2.5118611381562523\niqr:4.954797397665595\nCut Off: 7.432196096498393\nV10 Lower: -14.89885463232024\nV10 Upper: 4.92033495834214\nFeature V10 Outliers for Fraud Cases 27\nV10 outliers: [-15.2318333653018, -15.5637913387301, -18.9132433348732, -23.2282548357516, -15.5637913387301, -17.1415136412892, -22.1870885620007, -24.5882624372475, -15.2399619587112, -16.2556117491401, -18.2711681738888, -15.2399619587112, -15.1241628144947, -14.9246547735487, -16.7460441053944, -24.4031849699728, -19.836148851696, -15.1237521803455, -14.9246547735487, -16.6011969664137, -16.3035376590131, -22.1870885620007, -22.1870885620007, -22.1870885620007, -16.6496281595399, -15.3460988468775, -20.9491915543611]\nNumber of Instances after outliers removal 945\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["#lets  check outlier graphs\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,6))\n\ncolors = ['#B3F9C5', '#f9c5b3']\n\n#Boxplot with outliers removed\n\n#Feature V14\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df, ax=ax1, palette=colors)\nax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\nax1.annotate('Fewer extreme \\n ouliers', xy=(0.98, -17.5), xytext=(0, -12), arrowprops=dict(facecolor='black'), fontsize=14)\n\n#Feature V12\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=ax2, palette=colors)\nax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\nax2.annotate('Fewer extreme \\n ouliers', xy=(0.98, -17.5), xytext=(0, -12), arrowprops=dict(facecolor='black'), fontsize=14)\n\n#Feature V10\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=ax3, palette=colors)\nax3.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\nax3.annotate('Fewer extreme \\n ouliers', xy=(0.98, -17.5), xytext=(0, -12), arrowprops=dict(facecolor='black'), fontsize=14)\n\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["#Convert back from Pandas to dataframe\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window\n\ndfff = spark.createDataFrame(new_df)\nwin = Window().orderBy('Time')\ndfff = dfff.withColumn(\"idx\", row_number().over(win))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["#Machine learning model Gradient-Boosted Trees (GBTs) \nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import VectorIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.linalg import DenseVector\n\ntraining_df = dfff.rdd.map(lambda x: (DenseVector(x[0:29]),x[30],x[31])) # Dense Vector required in spark to train the data\ntraining_df = spark.createDataFrame(training_df,[\"features\",\"label\",\"index\"])\ntraining_df = training_df.select(\"index\",\"features\",\"label\")\n\n#Split Dataset to train and test\ntrain_data_after, test_data_after = training_df.randomSplit([.8,.2],seed=1234)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["#count the training data\ntrain_data_after.groupBy(\"label\").count().show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+\nlabel|count|\n+-----+-----+\n    0|  402|\n    1|  377|\n+-----+-----+\n\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["#Count testing data\ntest_data_after.groupBy(\"label\").count().show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+\nlabel|count|\n+-----+-----+\n    0|   86|\n    1|   80|\n+-----+-----+\n\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["#Train and predict using Gradient-Boosted Trees (GBTs) Classifier (First Classifier after handling imbalanced dataset)\ngbt = GBTClassifier(featuresCol=\"features\", maxIter=100,maxDepth=8)\nmodel = gbt.fit(train_data_after)\npredictions_gbt_after = model.transform(test_data_after)\npredictions_gbt_after.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\nprediction|count|\n+----------+-----+\n       0.0|   85|\n       1.0|   81|\n+----------+-----+\n\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["#We use the BinaryClassificationEvaluator to evaluate our models, which uses areaUnderROC as the default metric.\nevaluator_gbt_after = BinaryClassificationEvaluator()\nevaluator_gbt_after.evaluate(predictions_gbt_after)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[120]: 0.9655523255813958</div>"]}}],"execution_count":36},{"cell_type":"code","source":["#Check count of fraud and none fraud predictions\npredictions_gbt_after = predictions_gbt_after.withColumn(\"fraudPrediction\",when((predictions_gbt_after.label==1)&(predictions_gbt_after.prediction==1),1).otherwise(0))\npredictions_gbt_after.groupBy(\"fraudPrediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+-----+\nfraudPrediction|count|\n+---------------+-----+\n              1|   76|\n              0|   90|\n+---------------+-----+\n\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["#Calculated Recall\nfrom pyspark.sql.functions import col\naccurateFraud_gbt_after = predictions_gbt_after.groupBy(\"fraudPrediction\").count().where(predictions_gbt_after.fraudPrediction==1).head()[1]\ntotalFraud_gbt_after = predictions_gbt_after.groupBy(\"label\").count().where(predictions_gbt_after.label==1).head()[1]\nFraudPredictionAccuracy_gbt_after = (accurateFraud_gbt_after/totalFraud_gbt_after)*100\nprint(FraudPredictionAccuracy_gbt_after)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">95.0\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["#Calculating Confusion matrix\ntp_gbt_after = predictions_gbt_after[(predictions_gbt_after.label == 1) & (predictions_gbt_after.prediction == 1)].count()\ntn_gbt_after = predictions_gbt_after[(predictions_gbt_after.label == 0) & (predictions_gbt_after.prediction == 0)].count()\nfp_gbt_after = predictions_gbt_after[(predictions_gbt_after.label == 0) & (predictions_gbt_after.prediction == 1)].count()\nfn_gbt_after = predictions_gbt_after[(predictions_gbt_after.label == 1) & (predictions_gbt_after.prediction == 0)].count()\n\n\nprint(\"True Positive: \",tp_gbt_after,\"\\nTrue Negative: \",tn_gbt_after,\"\\nFalse Positive: \",fp_gbt_after,\"\\nFalse Negative: \",fn_gbt_after)\nprint(\"Recall: \",tp_gbt_after/(tp_gbt_after+fn_gbt_after))\nprint(\"Precision: \", tp_gbt_after/(tp_gbt_after+fp_gbt_after))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">True Positive:  76 \nTrue Negative:  81 \nFalse Positive:  5 \nFalse Negative:  4\nRecall:  0.95\nPrecision:  0.9382716049382716\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["##Train and predict using Random Forest Classifier Classifier (Second Classifier after handling imbalanced dataset)\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\nrfModel = rf.fit(train_data_after)\npredictions_rf_after = rfModel.transform(test_data_after)\npredictions_rf_after.groupBy(\"prediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\nprediction|count|\n+----------+-----+\n       0.0|   87|\n       1.0|   79|\n+----------+-----+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["#We use the BinaryClassificationEvaluator to evaluate our models, which uses areaUnderROC as the default metric.\nevaluatorrf_after = BinaryClassificationEvaluator()\nevaluatorrf_after.evaluate(predictions_rf_after)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[131]: 0.9707848837209305</div>"]}}],"execution_count":41},{"cell_type":"code","source":["#Check count of fraud and none fraud predictions\npredictions_rf_after = predictions_rf_after.withColumn(\"fraudPrediction\",when((predictions_rf_after.label==1)&(predictions_rf_after.prediction==1),1).otherwise(0))\npredictions_rf_after.groupBy(\"fraudPrediction\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+-----+\nfraudPrediction|count|\n+---------------+-----+\n              1|   75|\n              0|   91|\n+---------------+-----+\n\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["#Calculated Recall\nfrom pyspark.sql.functions import col\naccurateFraud_rf_after = predictions_rf_after.groupBy(\"fraudPrediction\").count().where(predictions_rf_after.fraudPrediction==1).head()[1]\ntotalFraud_rf_after = predictions_rf_after.groupBy(\"label\").count().where(predictions_rf_after.label==1).head()[1]\nFraudPredictionAccuracy_rf_after = (accurateFraud_rf_after/totalFraud_rf_after)*100\nprint(FraudPredictionAccuracy_rf_after)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">93.75\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["#Calculating Confusion matrix\ntp_rf_after = predictions_rf_after[(predictions_rf_after.label == 1) & (predictions_rf_after.prediction == 1)].count()\ntn_rf_after = predictions_rf_after[(predictions_rf_after.label == 0) & (predictions_rf_after.prediction == 0)].count()\nfp_rf_after = predictions_rf_after[(predictions_rf_after.label == 0) & (predictions_rf_after.prediction == 1)].count()\nfn_rf_after = predictions_rf_after[(predictions_rf_after.label == 1) & (predictions_rf_after.prediction == 0)].count()\n\n\nprint(\"True Positive: \",tp_rf_after,\"\\nTrue Negative: \",tn_rf_after,\"\\nFalse Positive: \",fp_rf_after,\"\\nFalse Negative: \",fn_rf_after)\nprint(\"Recall: \",tp_rf_after/(tp_rf_after+fn_rf_after))\nprint(\"Precision: \", tp_rf_after/(tp_rf_after+fp_rf_after))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">True Positive:  75 \nTrue Negative:  82 \nFalse Positive:  4 \nFalse Negative:  5\nRecall:  0.9375\nPrecision:  0.9493670886075949\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["#Plot a comparison between the results of the evaluation method between the two classifiers before and after handling imbalance dataset\nfrom sklearn import metrics\nimport numpy as np\n\n#GBT Clasiifier plot before handling imbalanced dataset\n\nlabel_array_gbt_before= np.array(test_data_before.select(\"label\").collect())\nlabel_array_gbt_before = label_array_gbt_before.flatten('F')\n#predictions_gbt_before = np.array(predictions_gbt_before.select(\"prediction\").collect())\nprint(type(predictions_gbt_before))\npredictions_gbt_before = predictions_gbt_before.flatten('F')\nfpr_gbt_before, tpr_gbt_before, thresh_gbt_before = metrics.roc_curve(label_array_gbt_before, predictions_gbt_before)\nauc_gbt_before = metrics.roc_auc_score(label_array_rf_before, predictions_rf_before)\nplt.plot(fpr_gbt_before,tpr_gbt_before,label=\"GBT Classifier before handle imbalance, auc=\"+str(auc_gbt_before))\n\n\n#Random Forest plot before handling imbalanced dataset\n\nlabel_array_rf_before= np.array(test_data_before.select(\"label\").collect())\nlabel_array_rf_before = label_array_rf_before.flatten('F')\n#predictions_rf_before = np.array(predictions_rf_before.select(\"prediction\").collect())\nprint(type(predictions_rf_before))\npredictions_rf_before = predictions_rf_before.flatten('F')\nfpr_rf_before, tpr_rf_before, thresh_rf_before = metrics.roc_curve(label_array_rf_before, predictions_rf_before)\nauc_rf_before = metrics.roc_auc_score(label_array_rf_before, predictions_rf_before)\nplt.plot(fpr_rf_before,tpr_rf_before,label=\"Random Forest before handle imbalance, auc=\"+str(auc_rf_before))\n\n\n#GBT Clasiifier plot after handling imbalanced dataset\n\nlabel_array_gbt_after= np.array(test_data_after.select(\"label\").collect())\nlabel_array_gbt_after = label_array_gbt_after.flatten('F')\n#predictions_gbt_after = np.array(predictions_gbt_after.select(\"prediction\").collect())\nprint(type(predictions_gbt_after))\npredictions_gbt_after = predictions_gbt_after.flatten('F')\nfpr_gbt_after, tpr_gbt_after, thresh_gbt_after = metrics.roc_curve(label_array_gbt_after, predictions_gbt_after)\nauc_gbt_after = metrics.roc_auc_score(label_array_gbt_after, predictions_gbt_after)\nplt.plot(fpr_gbt_after,tpr_gbt_after,label=\"GBT Classifier after handle imbalance, auc=\"+str(auc_gbt_after))\n\n#Random Forest plot before handling imbalanced dataset\n\nlabel_array_rf_after= np.array(test_data_after.select(\"label\").collect())\nlabel_array_rf_after = label_array_rf_after.flatten('F')\n#predictions_rf_after = np.array(predictions_rf_after.select(\"prediction\").collect())\nprint(type(predictions_rf_after))\npredictions_rf_after = predictions_rf_after.flatten('F')\nfpr_rf_after, tpr_rf_after, thresh_rf_after = metrics.roc_curve(label_array_rf_after, predictions_rf_after)\nauc_rf_after = metrics.roc_auc_score(label_array_rf_after, predictions_rf_after)\nplt.plot(fpr_rf_after,tpr_rf_after,label=\"Random Forest after handle imbalance, auc=\"+str(auc_rf_after))\n\nplt.legend(loc=0)\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# GBT Classifier accuracy and Random Forset classifiers are same around 94.5% after handling imbalanced dataset that is higher than GBT and Random Forest that are around 89.6 % \n#before handling imbalanced dataset"],"metadata":{},"outputs":[],"execution_count":46}],"metadata":{"name":"Hesham_Fraud","notebookId":1928815557791868},"nbformat":4,"nbformat_minor":0}
